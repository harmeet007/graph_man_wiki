{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework_3_2019spring_v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FhwQS2pyc4FW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2019\n",
        "\n",
        "\n",
        "# Homework 3:   Collaborative Filtering + Matrix Factorization\n",
        "\n",
        "### 100 points [6% of your final grade]\n",
        "\n",
        "### Due: Wednesday, March 27, 2019 by 11:59pm\n",
        "\n",
        "*Goals of this homework:* Understand how collaborative filtering and matrix factorization works. Explore different methods for real-world recommendation senarios.\n",
        "\n",
        "*Submission instructions (eCampus):* To submit your homework, rename this notebook as `UIN_hw3.ipynb`. For example, my homework submission would be something like `555001234_hw3.ipynb`. Submit this notebook via eCampus (look for the homework 3 assignment there). Your notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so). So please run all the cells for us, and then submit.\n",
        "\n",
        "*Late submission policy:* For this homework, you may use as many late days as you like (up to the 5 total allotted to you).\n",
        "\n",
        "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
        "\n",
        "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
        "\n",
        "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
      ]
    },
    {
      "metadata": {
        "id": "2vte4DuWc4FX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1. Collaborative Filtering (50 points)\n",
        "\n",
        "In this part, you will implement collaborative filtering on the [MovieLens Latest Datasets](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html). After removing users who left less than 20 ratings and movies with less than 20 ratings, the provided dataset has only ~1,200 items and ~500 users. You can also check the title and genres of each movie in *movies_info.csv*.\n",
        "\n",
        "As background, read [Collaborative Filtering Recommender Systems](http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf) and refer to the course slides `week06rec.pdf` for collaborative filtering."
      ]
    },
    {
      "metadata": {
        "id": "28DTuJsSc4FY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Load the Data\n",
        "\n",
        "Please download the dataset from Piazza. There are about 65,000 ratings in total. We split the rating data into two set. You will train with 70% of the data (in *train_movie.csv*) and test on the remaining 30% of data (in *test_movie.csv*). Each of train and test files has lines having this format: UserID, MovieID, Rating. \n",
        "\n",
        "First you will need to load the data and store it with any structure you like. Please report the numbers of unique users and movies in the dataset. "
      ]
    },
    {
      "metadata": {
        "id": "K5ryC7aQc4FZ",
        "colab_type": "code",
        "outputId": "07df70eb-0448-4ea4-e99e-d2f05a8aea43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# load the data, then print out the number of\n",
        "# movies and users in each of train and test sets.\n",
        "# Your Code Here...\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "train_data = pd.read_csv('train_movie.csv')\n",
        "test_data = pd.read_csv('test_movie.csv')\n",
        "\n",
        "print('Unique users count:', len(train_data.userId.unique()+test_data.userId.unique()))\n",
        "print('Unique movies count: ', len(train_data.movieId.unique()+test_data.movieId.unique()))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique users count: 541\n",
            "Unique movies count:  1211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qNdSy2tJc4Fc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 Implement User-based Collaborative Filtering\n",
        "\n",
        "In this part, you will implement the basic Userâ€“User Collaborative Filtering algorithm introduced in the class. Given the ratings by each user, you are going to try different methods in calculating the similarities between users. You will use equation `(c)` in `week06rec.pdf` (Page 40) to aggregate ratings. Set k = 0.05. Just consider all users as neighbors. That is, while predicting how user $u$ will rate item $i$, $\\widehat{C}$ includes all users who have ratings on i in the training set.\n",
        "\n",
        "*For this memory-based algorithm, you can only rely on the ratings in training set to predict for the testing set. That is, you assume that you don't know any ratings information in the test set except that when you evalaute your model.*"
      ]
    },
    {
      "metadata": {
        "id": "Zx7Zqu9Mc4Fd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity\n",
        "\n",
        "First, you will try to calculate the similarity between users with cosine similary following the equation on page 16 of [Collaborative Filtering Recommender Systems](http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf). And then you need to predict the rating for each (user, movie) tuple in the test set. *Note: you don't need to subtract user mean baseline from the ratings prior to computing the similarity.*"
      ]
    },
    {
      "metadata": {
        "id": "ShKLjwywc4Fe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Predict for test set\n",
        "# for item in train_data.movieId.unique():\n",
        "#         domain = df.index[df['movieId']==item].tolist()\n",
        "def cosSim(user,target_user,target_movie,train_data,test_data):\n",
        "    num = 0\n",
        "    den,den1,den2,avg_rating,avg_target = 0,0,0,0,0\n",
        "    #for item in train_data.userId.unique():\n",
        "    domain_A = train_data.index[train_data['userId']==user].tolist()\n",
        "    test_domain_A = test_data.index[test_data['userId']==user].tolist()\n",
        "    domain_B = train_data.index[train_data['userId']==target_user].tolist()\n",
        "    test_domain_B = test_data.index[test_data['userId']==target_user].tolist()\n",
        "    mov_A,mov_B = {},{}\n",
        "    for ind in domain_A:\n",
        "        mov_A[train_data.at[ind,'movieId']] = train_data.at[ind,'rating']\n",
        "    for ind in domain_B:\n",
        "        mov_B[train_data.at[ind,'movieId']] = train_data.at[ind,'rating']\n",
        "    test_mov_A,test_mov_B = {},{}\n",
        "    for ind in test_domain_A:\n",
        "        test_mov_A[test_data.at[ind,'movieId']] = test_data.at[ind,'rating']\n",
        "    for ind in test_domain_B:\n",
        "        test_mov_B[test_data.at[ind,'movieId']] = test_data.at[ind,'rating']\n",
        "    comm = list(set(mov_A.keys()).intersection(mov_B.keys()))\n",
        "    for movie in comm:\n",
        "        num += (mov_A[movie]*mov_B[movie])\n",
        "    for movie in mov_A:\n",
        "        den1 += mov_A[movie]**2\n",
        "    for movie in test_mov_A:\n",
        "        avg_rating += test_mov_A[movie]\n",
        "    for movie in mov_B:\n",
        "        den2 += mov_B[movie]**2\n",
        "    for movie in test_mov_B:\n",
        "        avg_target += test_mov_B[movie]\n",
        "    den = math.sqrt(den1)*math.sqrt(den2)\n",
        "    return ((num/den), (avg_rating/len(test_domain_A)), (avg_target/len(test_domain_B)), (test_mov_A.get(target_movie,0)))\n",
        "\n",
        "\n",
        "def predictModel(user_list,target_user,target_movie,train_data,test_data,k=0.05):\n",
        "    r = 0\n",
        "    for user in user_list:                       \n",
        "        similarity, avg_user_rating, avg_target_rating, user_rating = cosSim(user,target_user,target_movie,train_data,test_data)\n",
        "        r += similarity*(user_rating - avg_user_rating)\n",
        "    return (avg_target_rating + k*r)\n",
        "\n",
        "def neighbours(target_movie,target_user,train_data):\n",
        "    index_list = train_data.index[train_data['movieId']==target_movie].tolist()\n",
        "    user_list = [train_data.at[ind,'userId'] for ind in index_list]\n",
        "    if target_user in user_list:\n",
        "        user_list.remove(target_user)\n",
        "    return user_list \n",
        "    \n",
        "def CF(test_data,train_data):\n",
        "    all_users = test_data.userId.unique()\n",
        "    all_movies = test_data.movieId.unique()\n",
        "    rating = {}\n",
        "    for target_user in all_users[:10]:\n",
        "        rating[target_user] = []\n",
        "        for target_movie in all_movies[:10]:\n",
        "            user_list = neighbours(target_movie,target_user,train_data)\n",
        "            rating[target_user].append(predictModel(user_list,target_user,target_movie,train_data,test_data))\n",
        "    return rating\n",
        "\n",
        "predicted_rating = CF(test_data,train_data)          \n",
        "       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVb5tt0Sc4Fg",
        "colab_type": "code",
        "outputId": "ef464c60-e07b-49e3-acf5-b832a5268abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "cell_type": "code",
      "source": [
        "for i in predicted_rating.keys():\n",
        "  print(i, predicted_rating[i])\n",
        "  \n",
        "for i in test_data.userId.unique()[:10]:\n",
        "  temp = test_data.index[test_data['userId']==i].tolist()\n",
        "  for j in temp:\n",
        "    print(test_data.at[j,'rating'],end=', ')\n",
        "  print()\n",
        "    \n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [2.3413500220332133, 2.936448600199732, 2.9763749081636464, 3.5485658934621296, 2.7060453405518166, 3.68782859802916, 3.1485475784776478, 1.176872460667565, 3.2114062835540027, 2.4906911138075003]\n",
            "1 [3.8719487416640526, 4.096558154008376, 4.010431718966637, 4.140618327813155, 3.5123158839036392, 4.164689185542374, 4.022817111983288, 3.0396145400406036, 4.01641637373276, 3.6562669778102537]\n",
            "2 [0.7275579713322888, 0.7799875233520351, 0.6945035907516561, 0.8802350042719611, 0.7757843737661942, 0.9522257717124902, 0.8546615578537875, 0.5998023622459202, 0.8685082531401824, 0.8467269430701704]\n",
            "3 [2.018894320482487, 2.3796327325153843, 2.412131000211609, 2.78433004921818, 2.229973625645649, 2.7914383503946283, 2.4178237302586245, 1.1239821850704508, 2.466563319229225, 2.0437103136143255]\n",
            "4 [2.639888130906669, 2.9186393446022576, 2.8822913701570236, 3.182812179061996, 2.8220632075875285, 3.2337789635377816, 2.9761472119406966, 2.067458938839745, 2.904243172726057, 2.5997484179463153]\n",
            "5 [2.2906193534155643, 2.707258038981022, 2.6635597635164445, 3.0484911646030635, 2.6230162941342154, 3.19351762911918, 2.8126880150618194, 1.821963324986744, 2.6805222141277047, 2.316145911390007]\n",
            "6 [1.711680257457, 2.2722819836154713, 2.189663866492347, 2.6490954038978565, 1.7489271912435174, 2.7472468098243206, 2.2572937236600628, 0.6726370512876807, 2.287423596575672, 1.3911831432547677]\n",
            "7 [2.160596445238567, 2.609231168094349, 2.561516689786198, 2.9588005962725763, 2.342667616122395, 3.0547906927043567, 2.731749598035761, 1.419162759683073, 2.631820016883767, 2.0977612423612184]\n",
            "8 [2.9755440023026534, 3.1572227846790724, 3.181555766938265, 3.3626759755224103, 3.0341120838932065, 3.398925838893827, 3.1090173948786086, 2.5681443769823007, 3.244617603752831, 2.790668843384723]\n",
            "9 [2.472373710350168, 2.7652060426620775, 2.653481003553927, 2.800719047288108, 2.312795959720798, 2.8677154407317147, 2.573826326580413, 1.840944966353671, 2.6975814711388306, 2.1084610037192215]\n",
            "4, 5, 5, 5, 5, 5, 3, 5, 3, 4, 5, 4, 5, 5, 4, 3, 5, 5, 5, 5, 4, 4, 4, 5, 5, 3, 2, 5, 5, 4, 3, 5, 3, 5, 3, 4, 4, 4, 5, 4, 4, 5, 4, 4, 5, 5, 3, 5, 4, 5, 4, 5, 5, 3, \n",
            "3, 4, 4, 5, 4, 5, 5, \n",
            "3, 0, 4, 0, 0, 0, 0, \n",
            "4, 4, 3, 5, 3, 4, 4, 1, 3, 4, 4, 1, 3, 1, 4, 3, 4, 4, 4, 5, 2, 3, 5, 3, 1, 3, 2, 4, 2, 3, 5, 5, 4, 5, 4, 4, 3, 1, 1, 4, 4, \n",
            "3, 4, 4, 4, 2, 4, 3, 4, 4, 3, 5, 2, 3, \n",
            "3, 3, 3, 4, 5, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 1, 3, 5, 3, 3, 3, 3, 4, 3, 2, 4, 4, 2, 3, 4, 5, 4, 4, 3, 4, 4, 3, 5, 3, 5, 4, 4, 5, \n",
            "4, 5, 5, 4, 5, 1, 2, 1, 3, 2, 4, 1, 4, 3, 3, 3, 4, 4, 3, 4, 4, 1, 4, 1, 3, 4, 1, 4, 4, 4, 2, 4, 5, 2, 5, 3, 1, \n",
            "3, 3, 4, 5, 3, 3, 1, 4, 2, 3, 4, 3, 3, 5, 4, \n",
            "5, 2, 3, 4, 5, 3, 3, \n",
            "3, 3, 5, 4, 3, 3, 3, 4, 0, 3, 3, 4, 3, 3, 3, 4, 4, 0, 4, 3, 4, 1, 3, 3, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c7fby80vc4Fi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "You should evaluate your predictions using Mean Absolute Error and Root Mean Squared Error. "
      ]
    },
    {
      "metadata": {
        "id": "5DAVI9U8c4Fj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Report Mean Absolute Error and Root Mean Squared Error for test set\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pmuq_5Xfc4Fl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pearson correlation\n",
        "\n",
        "Then, you will try to calculate the similarity between users with pearson correlation following `week06rec.pdf` (Page 37). And then you need to predict the rating for each (user, movie) tuple in the test set."
      ]
    },
    {
      "metadata": {
        "id": "XPfZRPscc4Fm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Predict for test set\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ea9TEOf6c4Fo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "You should evaluate your predictions using Mean Absolute Error and Root Mean Squared Error. "
      ]
    },
    {
      "metadata": {
        "id": "fStbuluSc4Fp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Report Mean Absolute Error and Root Mean Squared Error for test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MFOF4o_4c4Ft",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pearson correlation (varying the threshold)\n",
        "\n",
        "In [Collaborative Filtering Recommender Systems](http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf), they observe that: \n",
        "\n",
        "> Pearson correlation suffers from computing high similarity\n",
        "between users with few ratings in common. This can be alleviated by setting a threshold on the number of co-rated items\n",
        "necessary for full agreement (correlation of 1) and scaling the\n",
        "similarity when the number of co-rated items falls below this\n",
        "threshold.\n",
        "\n",
        "So now revise your Pearson to consider a threshold. Try several values and report for one that you think is appropriate."
      ]
    },
    {
      "metadata": {
        "id": "4Q3UEx8tc4Fu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Predict for test set\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aswwhSdQc4Fx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "You should evaluate your predictions using Mean Absolute Error and Root Mean Squared Error. "
      ]
    },
    {
      "metadata": {
        "id": "WtzfB64dc4Fx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Report Mean Absolute Error and Root Mean Squared Error for test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWUiFEkmc4Fz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What do you observe? How different are your results for the original Pearson Correlation approach vs. the thresholded version vs. the Cosine Similarity approach? Why do you think this is? *provide a brief (1-2 paragraph) discussion based on these questions.*"
      ]
    },
    {
      "metadata": {
        "id": "-sURFAK3c4F0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAs3hnBuc4F2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2. MF (20 points)\n",
        "\n",
        "In class, we introduced how matrix factorization works for recommendation. Now it is your term to implement it. There are different methods to obtain the latent factor matrices **P** and **Q**, like gradient descent, Alternating Least Squares (ALS), and so on. Pick one of them and implement your MF model. *You can refer to tutorials and resources online. Remember our **collaboration policy** and you need to inform us of the resources you refer to.* \n",
        "\n",
        "Please report MAE and RMSE of your MF model for the test set. *You are expected to get a lower MAE and RMSE compared with the results in Part 1.*"
      ]
    },
    {
      "metadata": {
        "id": "fKMXT7SZc4F4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Report Mean Absolute Error and Root Mean Squared Error for test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zg-berkhc4F6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Which method did you use to obtain **P** and **Q**? What are the advantages and disadvantages of the method you pick? *provide a brief (1-2 paragraph) discussion based on these questions.*"
      ]
    },
    {
      "metadata": {
        "id": "mNwy1VhAc4F6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PGsXpiXLc4F8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 3. Extension (30 points)\n",
        "\n",
        "Given your results in the previous parts, can you do better? For this last part you should report on your best attempt at improving MAE and RMSE. Provide code, results, plus a brief discussion on your approach. Hints: You may consider using the title or genres information, trying other algorithms, designing a hybrid system, and so on. *As in the last homework, you can do anything you like to improve MAE and RMSE.*\n",
        "\n",
        "You will get full marks for this part if you get better results than both of your CF and MF (of course we will also judge whether what you do here is reasonable or not). Additionally, you will get 5 points as bonus if your model performs the best among the whole class."
      ]
    },
    {
      "metadata": {
        "id": "nv2JY9Awc4F9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Your Code Here...\n",
        "# Report Mean Absolute Error and Root Mean Squared Error for test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pZtpfSTFc4GA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Please explain what you do to improve the recommendation in 1-2 paragraphs."
      ]
    },
    {
      "metadata": {
        "id": "RRdprsFGc4GA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_cg1Gvk6c4GD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Collaboration declarations"
      ]
    },
    {
      "metadata": {
        "id": "D7HFmSLAc4GE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*If you collaborated with anyone (see Collaboration policy at the top of this homework), you can put your collaboration declarations here.*"
      ]
    },
    {
      "metadata": {
        "id": "6leibuD0c4GF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}